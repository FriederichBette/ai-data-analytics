# ğŸš€ Data Analytics LLM - NatÃ¼rlichsprachliche Datenbank-Abfragen

Ein vollstÃ¤ndiges System fÃ¼r automatische Datenintegration, Standardisierung und LLM-basierte SQL-Abfragen.

## ğŸ“‹ Features

- **Automatische Datenintegration**: Web Scraping & API-Integration
- **ETL Pipeline**: Datenstandardisierung und -validierung
- **Data Marts**: Strukturierte Datenspeicherung in Supabase
- **LLM Text-to-SQL**: NatÃ¼rlichsprachliche Abfragen (OpenAI oder Ollama)
- **Interaktives UI**: Dashboard fÃ¼r Datenabfragen und Visualisierung
- **Hybride Speicherung**: Strukturierte Daten + Vektoren (optional)

## ğŸ—ï¸ Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend  â”‚  Next.js Dashboard
â”‚   (Next.js) â”‚  NatÃ¼rlichsprachliche Eingabe
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚   Backend   â”‚  Python FastAPI
â”‚   (Python)  â”‚  - LLM Integration (OpenAI/Ollama)
â”‚             â”‚  - ETL Pipeline
â”‚             â”‚  - Data Validation
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚  Supabase   â”‚  PostgreSQL Database
â”‚  (Postgres) â”‚  - Data Marts (Sales, Products, etc.)
â”‚             â”‚  - pgvector (optional)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### 1. Backend Setup

```bash
cd backend
python -m venv venv
venv\Scripts\activate  # Windows
pip install -r requirements.txt
```

### 2. Umgebungsvariablen konfigurieren

Kopiere `.env.example` zu `.env` und fÃ¼lle die Werte aus:

```bash
cp .env.example .env
```

### 3. Datenbank initialisieren

```bash
cd database
# Schema in Supabase importieren (siehe database/README.md)
```

### 4. Backend starten

```bash
cd backend
python main.py
```

### 5. Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

Ã–ffne http://localhost:3000

## ğŸ“ Projektstruktur

```
data-analytics-llm/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ etl/              # ETL Pipelines
â”‚   â”œâ”€â”€ scrapers/         # Web Scraping Module
â”‚   â”œâ”€â”€ llm/              # LLM Text-to-SQL
â”‚   â”œâ”€â”€ api/              # FastAPI Endpoints
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/          # Next.js App Router
â”‚   â”‚   â”œâ”€â”€ components/   # React Components
â”‚   â”‚   â””â”€â”€ lib/          # Utilities
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ schema.sql        # Supabase Schema
â”‚   â”œâ”€â”€ migrations/       # DB Migrations
â”‚   â””â”€â”€ seed_data.sql     # Demo Daten
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ”‘ Konfiguration

### LLM Provider wÃ¤hlen

In `.env`:

**OpenAI (Cloud)**:
```
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-...
```

**Ollama (Lokal)**:
```
LLM_PROVIDER=ollama
OLLAMA_MODEL=llama3
OLLAMA_BASE_URL=http://localhost:11434
```

## ğŸ“Š Beispiel-Abfragen

- "Zeige mir die Top 10 VerkÃ¤ufe im August sortiert nach Umsatz"
- "Welche Produkte haben die hÃ¶chste Marge?"
- "Wie viele Kunden haben wir in Deutschland?"
- "Vergleiche Umsatz Q1 vs Q2 2024"

## ğŸ› ï¸ Technologie-Stack

- **Backend**: Python, FastAPI, SQLAlchemy
- **Frontend**: Next.js 14, React, TypeScript, Tailwind CSS
- **Database**: Supabase (PostgreSQL + pgvector)
- **LLM**: OpenAI GPT-4 oder Ollama (Llama 3)
- **ETL**: Pandas, BeautifulSoup, Requests

## ğŸ“ Lizenz

MIT
