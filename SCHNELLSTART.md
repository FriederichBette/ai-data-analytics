# ğŸš€ Schnellstart-Anleitung

## âœ… Phase 1 - ABGESCHLOSSEN!

Dein Projekt ist jetzt vollstÃ¤ndig eingerichtet! Hier sind die nÃ¤chsten Schritte:

## ğŸ“ Projektstandort

```
C:\Users\user\.gemini\antigravity\scratch\data-analytics-llm\
```

**WICHTIG**: Ã–ffne diesen Ordner als Workspace in deinem Editor!

---

## ğŸ”§ Schritt 1: Datenbank einrichten (5 Minuten)

### 1.1 Schema importieren

1. Ã–ffne dein Supabase Dashboard: https://supabase.com/dashboard/project/vauipkbigugewcqgnowk
2. Klicke auf **SQL Editor** (linke Sidebar)
3. Klicke auf **New Query**
4. Ã–ffne die Datei `database/schema.sql` in diesem Projekt
5. Kopiere den gesamten Inhalt und fÃ¼ge ihn im SQL Editor ein
6. Klicke auf **Run** (oder Ctrl+Enter)

âœ… Du solltest sehen: "Tables created successfully"

### 1.2 Demo-Daten laden

1. Im SQL Editor, klicke auf **New Query**
2. Ã–ffne die Datei `database/seed_data.sql`
3. Kopiere den Inhalt und fÃ¼ge ihn ein
4. Klicke auf **Run**

âœ… Du solltest sehen: 20 Products, 50 Customers, 200 Sales

---

## ğŸ Schritt 2: Backend starten (2 Minuten)

### 2.1 Python Virtual Environment erstellen

```powershell
cd C:\Users\user\.gemini\antigravity\scratch\data-analytics-llm\backend
python -m venv venv
.\venv\Scripts\activate
```

### 2.2 Dependencies installieren

```powershell
pip install -r requirements.txt
```

### 2.3 Backend starten

```powershell
python main.py
```

âœ… Backend lÃ¤uft auf: http://localhost:8000

**Teste es**: Ã–ffne http://localhost:8000 im Browser - du solltest sehen:
```json
{
  "status": "online",
  "service": "Data Analytics LLM API"
}
```

---

## ğŸ¨ Schritt 3: Frontend starten (2 Minuten)

### 3.1 Dependencies installieren

Ã–ffne ein **NEUES Terminal** (lass das Backend laufen!):

```powershell
cd C:\Users\user\.gemini\antigravity\scratch\data-analytics-llm\frontend
npm install
```

### 3.2 Frontend starten

```powershell
npm run dev
```

âœ… Frontend lÃ¤uft auf: http://localhost:3000

---

## ğŸ‰ Schritt 4: Erste Abfrage testen!

1. Ã–ffne http://localhost:3000 im Browser
2. Du siehst ein schÃ¶nes Dashboard mit Gradient-Hintergrund
3. Gib eine Frage ein, z.B.:
   - "Zeige mir alle Produkte"
   - "Welche Kunden haben wir in Deutschland?"
   - "Top 10 VerkÃ¤ufe sortiert nach Umsatz"
4. Klicke auf **Abfrage starten**

**Hinweis**: Ohne OpenAI/Ollama werden Demo-Queries verwendet. Das System funktioniert trotzdem!

---

## ğŸ¤– Optional: LLM konfigurieren

### Option A: Ollama (Kostenlos, Lokal)

Wenn du Ollama bereits installiert hast:

```powershell
# Starte Ollama
ollama serve

# In einem neuen Terminal:
ollama pull llama3
```

Die `.env` Datei ist bereits auf Ollama konfiguriert!

### Option B: OpenAI (Bezahlt, Cloud)

1. Erstelle einen API Key: https://platform.openai.com/api-keys
2. Ã–ffne die Datei `.env` im Projekt-Root
3. Ã„ndere:
   ```
   LLM_PROVIDER=openai
   OPENAI_API_KEY=sk-dein-key-hier
   ```
4. Starte das Backend neu

---

## ğŸ“Š Beispiel-Abfragen zum Testen

- "Zeige mir die Top 10 VerkÃ¤ufe im August sortiert nach Umsatz"
- "Welche Produkte haben die hÃ¶chste Marge?"
- "Wie viele Kunden haben wir in Deutschland?"
- "Liste alle Electronics Produkte"
- "Zeige mir alle VerkÃ¤ufe von heute"

---

## ğŸ› Troubleshooting

### Backend startet nicht?
- PrÃ¼fe ob Python installiert ist: `python --version`
- PrÃ¼fe ob venv aktiviert ist (du solltest `(venv)` im Terminal sehen)
- PrÃ¼fe die Supabase Credentials in `.env`

### Frontend startet nicht?
- PrÃ¼fe ob Node.js installiert ist: `node --version`
- LÃ¶sche `node_modules` und fÃ¼hre `npm install` erneut aus

### Keine Daten in der Datenbank?
- Hast du `schema.sql` und `seed_data.sql` ausgefÃ¼hrt?
- PrÃ¼fe im Supabase Dashboard unter "Table Editor"

### LLM funktioniert nicht?
- Das ist OK! Das System nutzt Demo-Queries als Fallback
- FÃ¼r echte Text-to-SQL: Installiere Ollama oder fÃ¼ge OpenAI Key hinzu

---

## ğŸ“ Projektstruktur

```
data-analytics-llm/
â”œâ”€â”€ backend/           # Python FastAPI Backend
â”‚   â”œâ”€â”€ api/          # Database Manager
â”‚   â”œâ”€â”€ llm/          # Text-to-SQL Engine
â”‚   â””â”€â”€ main.py       # Hauptdatei
â”œâ”€â”€ frontend/         # Next.js Frontend
â”‚   â”œâ”€â”€ app/          # Pages
â”‚   â””â”€â”€ components/   # React Components
â”œâ”€â”€ database/         # SQL Schema & Seed Data
â””â”€â”€ .env             # Konfiguration (nicht in Git!)
```

---

## ğŸ¯ NÃ¤chste Schritte (Phase 2+)

- [ ] ETL Pipeline fÃ¼r echte Datenquellen
- [ ] Web Scraping Module
- [ ] Erweiterte Visualisierungen
- [ ] Vektorsuche mit pgvector
- [ ] Query-Historie speichern
- [ ] Export-Funktionen (CSV, Excel)

---

## ğŸ’¡ Tipps

- **Git**: Dein Projekt ist bereits ein Git Repository!
  ```powershell
  git status
  git log
  ```

- **Workspace**: Ã–ffne den Ordner als Workspace:
  ```
  C:\Users\user\.gemini\antigravity\scratch\data-analytics-llm
  ```

- **Dokumentation**: Alle Details findest du in `README.md`

---

## ğŸ†˜ Hilfe benÃ¶tigt?

Frag mich einfach! Ich kann dir helfen mit:
- Debugging
- Neue Features hinzufÃ¼gen
- Datenquellen integrieren
- Performance-Optimierung

**Viel Erfolg! ğŸš€**
